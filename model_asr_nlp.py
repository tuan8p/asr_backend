from transformers import pipeline, AutoTokenizer, AutoModel
import torch
from sklearn.metrics.pairwise import cosine_similarity
# import re

device = 0 if torch.cuda.is_available() else -1

print(f"üì¶ ƒêang load ASR model l√™n {'GPU' if device == 0 else 'CPU'}...")

asr_pipeline = pipeline(
    "automatic-speech-recognition",
    model="whisper-small-vi",
    device=device
)

print("‚úÖ ASR model ƒë√£ s·∫µn s√†ng.")

print(f"üì¶ ƒêang load NLP model l√™n {'GPU' if device == 0 else 'CPU'}...")

tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", trust_remote_code=True)
model = AutoModel.from_pretrained("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", trust_remote_code=True, use_safetensors=True)

print("‚úÖ NLP model ƒë√£ s·∫µn s√†ng.")

def get_sentence_embedding(sentence: str) -> torch.Tensor:
    """Chuy·ªÉn c√¢u th√†nh vector embedding trung b√¨nh (mean pooling)."""
    input_ids = tokenizer.encode(sentence, return_tensors='pt')
    with torch.no_grad():
        outputs = model(input_ids)
        last_hidden_state = outputs[0]  # (1, seq_len, hidden_dim)
        sentence_embedding = last_hidden_state.mean(dim=1)  # (1, hidden_dim)
    return sentence_embedding.squeeze(0)  # (hidden_dim,)

# M·∫´u c√¢u l·ªánh v√† intent t∆∞∆°ng ·ª©ng
intent_templates = {
    "b·∫≠t ƒë√®n": "TURN_ON_LIGHT",
    # "m·ªü ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n b·∫≠t": "TURN_ON_LIGHT",
    "kh√¥ng t·∫Øt ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n s√°ng": "TURN_ON_LIGHT",
    "t·ªëi qu√°": "TURN_ON_LIGHT",
    "kh√¥ng th·∫•y g√¨": "TURN_ON_LIGHT",
    "t·ªëi nh∆∞ m·ª±c": "TURN_ON_LIGHT",
    "t·ªëi r·ªìi": "TURN_ON_LIGHT",
    # "ƒë√®n t·∫Øt": "TURN_OFF_LIGHT",
    "t·∫Øt ƒë√®n": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng s√°ng": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng m·ªü": "TURN_OFF_LIGHT",
    "kh√¥ng b·∫≠t ƒë√®n": "TURN_OFF_LIGHT",
    "s√°ng qu√°": "TURN_OFF_LIGHT",
    "ch√≥i qu√°": "TURN_OFF_LIGHT",
    "s√°ng r·ªìi": "TURN_OFF_LIGHT",

    "b·∫≠t qu·∫°t": "TURN_ON_FAN",
    "t·∫Øt qu·∫°t": "TURN_OFF_FAN",
    # "qu·∫°t ch·∫°y": "TURN_ON_FAN",
    "qu·∫°t kh√¥ng ng·ª´ng": "TURN_ON_FAN",
    "n√≥ng qu√°": "TURN_ON_FAN",
    "h·∫ßm qu√°": "TURN_ON_FAN",
    # "m·ªü qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t m·ªü": "TURN_ON_FAN",
    "qu·∫°t ng·ª´ng": "TURN_OFF_FAN",
    # "qu·∫°t kh√¥ng ch·∫°y": "TURN_OFF_FAN",
    "kh√¥ng t·∫Øt qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t kh√¥ng m·ªü": "TURN_OFF_FAN",
    "kh√¥ng b·∫≠t qu·∫°t": "TURN_OFF_FAN",
    "l·∫°nh qu√°": "TURN_OFF_FAN",
    # "r√©t qu√°": "TURN_OFF_FAN",

    "m·ªü c·ª≠a": "OPEN_DOOR",
    "m·ªü kh√≥a c·ª≠a": "OPEN_DOOR",
    "t·∫Øt kh√≥a c·ª≠a": "OPEN_DOOR",
    # "c·ª≠a m·ªü": "OPEN_DOOR",
    "kh√¥ng ƒë√≥ng c·ª≠a": "OPEN_DOOR",
    # "t√¥i chu·∫©n b·ªã ra ngo√†i": "OPEN_DOOR",
    "t√¥i s·∫Øp ra ngo√†i": "OPEN_DOOR",
    "t√¥i chu·∫©n b·ªã v·ªÅ nh√†": "OPEN_DOOR",
    # "t√¥i ƒëi ra ngo√†i": "OPEN_DOOR",
    "ƒë√≥ng c·ª≠a": "CLOSE_DOOR",
    "kh√≥a c·ª≠a": "CLOSE_DOOR",
    # "c·ª≠a ƒë√≥ng": "CLOSE_DOOR",
    "kh√¥ng m·ªü c·ª≠a": "CLOSE_DOOR",
    "t√¥i ra ngo√†i r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ nh√† r·ªìi": "CLOSE_DOOR",
    "t√¥i v√¥ nh√† r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ r·ªìi": "CLOSE_DOOR",

    "b·∫≠t ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_CLOSE_DOOR",
    "t·∫Øt ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_OPEN_DOOR",
    "b·∫≠t ch·∫ø ƒë·ªô an ninh": "CLOSE_DOOR_AND_TURN_ON_FACE_DETECTION",
    "t·∫Øt ch·∫ø ƒë·ªô an ninh": "OPEN_DOOR_AND_TURN_OFF_FACE_DETECTION",
    "b·∫≠t t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_OPEN_DOOR",
    "t·∫Øt t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_CLOSE_DOOR",
}

# H√†m embedding
def get_sentence_embedding(sentence: str) -> torch.Tensor:
    input_ids = tokenizer.encode(sentence, return_tensors='pt')
    with torch.no_grad():
        outputs = model(input_ids)
        last_hidden_state = outputs[0]
        sentence_embedding = last_hidden_state.mean(dim=1)
    return sentence_embedding.squeeze(0)

# L∆∞u s·∫µn embeddings c·ªßa intent m·∫´u
template_embeddings = {k: get_sentence_embedding(k) for k in intent_templates.keys()}

# Tr√≠ch xu·∫•t ƒëi·ªÅu ki·ªán s·ªë (temperature, humidity, time)
def extract_numeric_condition(sentence: str) -> dict:
    patterns = [
        # Nhi·ªát ƒë·ªô
        (# vd: nhi·ªát ƒë·ªô kho·∫£ng 30 ƒë·ªô C
            r"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) .*? (\d+)? .*?",
            "temperature"
        ),
        (# vd: nhi·ªát ƒë·ªô 30 ƒë·ªô C
            r"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) (\d+)? .*?",
            "temperature"
        ),
        (# vd: nhi·ªát ƒë·ªô cao/th·∫•p
            r"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) .*?",
            "temperature"
        ),
        (
            r"(n√≥ng|l·∫°nh)",
            "temperature"
        ),
        # ƒê·ªô ·∫©m
        (# vd: ƒë·ªô ·∫©m kho·∫£ng 70%
            r"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) .*? (\d+)?",
            "humidity"
        ),
        (# vd: ƒë·ªô ·∫©m 70%
            r"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) (\d+)? .*?",
            "humidity"
        ),
        (# vd: ƒë·ªô ·∫©m cao/th·∫•p/kh√¥/·∫©m/√≠t/nhi·ªÅu
            r"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) .*?",
            "humidity"
        ),
        (
            r"(·∫©m|n·ªìm|kh√¥)",
            "humidity"
        ),
        # √Ånh s√°ng
        (
            r"(s√°ng|t·ªëi)",
            "light"
        ),
        # Qu·∫°t
        (# vd: m·ª©c kho·∫£ng 70%
            r"(m·ª©c|t·ªëc ƒë·ªô|quay) .*? (\d+)?",
            "fan"
        ),
        (# vd: m·ª©c 70%
            r"(m·ª©c|t·ªëc ƒë·ªô|quay) (\d+)? .*?",
            "fan"
        ),
        (# vd: m·ª©c 1/2/3
            r"(m·ª©c|t·ªëc ƒë·ªô) (\d+)?",
            "fan"
        ),
        (# vd: m·ª©c cao/th·∫•p/v·ª´a
            r"(m·ª©c|t·ªëc ƒë·ªô|quay) .*?",
            "fan"
        ),
        (
            r"(nhanh|m·∫°nh|cao|ch·∫≠m|y·∫øu|th·∫•p|v·ª´a|th∆∞·ªùng)",
            "fan"
        ),
        # Th·ªùi gian
        (
            r"(sau)\s*"
            r"(?:(?P<hour>\d+)\s*(gi·ªù|h|g)\s*)?"
            r"(?:(?P<minute>\d+)\s*(ph√∫t|p|m)\s*)?"
            r"(?:(?P<second>\d+)\s*(gi√¢y|s))?",
            "time"
        )
    ]

    for pattern, sensor in patterns:
        match = re.search(pattern, sentence, re.IGNORECASE)
        # print(pattern)
        if match:
            val = None
            unit = ""
            op = "="

            if any(kw in sentence for kw in ["tr√™n", "n√≥ng", "nhi·ªÅu h∆°n", "·∫©m", "n·ªìm", "cao"]):
                op = ">"
                if "ƒë·ªô ·∫©m" in sentence and not any(kw in sentence for kw in ["tr√™n", "nhi·ªÅu h∆°n", "n·ªìm", "cao"]):
                    op = "="
            elif any(kw in sentence for kw in ["d∆∞·ªõi", "l·∫°nh", "√≠t h∆°n", "kh√¥", "th·∫•p"]):
                op = "<"
            print(f"match: {match.groups()}")
            if sensor == "time":
                unit = "seconds"
                hour = int(match.group("hour")) if match.group("hour") else 0
                minute = int(match.group("minute")) if match.group("minute") else 0
                second = int(match.group("second")) if match.group("second") else 0
                val = hour * 3600 + minute * 60 + second
            elif sensor == "temperature":
                unit = "¬∞C"
                if len(match.groups()) > 1:
                    if match.group(2):
                        op = "="
                        val = int(match.group(2))
                        if any(kw in sentence for kw in ["ƒë·ªô k", "¬∞k", "¬∞ka", "ƒë·ªô ka", "ƒë·ªô ca", "¬∞ca"]) and "ƒë·ªô kho·∫£ng" not in sentence:
                            val -= 273
                elif any(kw in sentence for kw in ["n√≥ng", "cao"]):
                    val = 30
                elif any(kw in sentence for kw in ["l·∫°nh", "th·∫•p"]):
                    val = 20
            elif sensor == "humidity":
                unit = "%"
                if len(match.groups()) > 1:
                    if match.group(2):
                        op = "="
                        val = int(match.group(2))
                elif any(kw in sentence for kw in ["kh√¥", "th·∫•p", "√≠t"]):
                    val = 30
                elif "n·ªìm" in sentence:
                    val = 90
                elif any(kw in sentence for kw in ["cao", "nhi·ªÅu"]):
                    val = 70
                elif "·∫©m" in sentence and "ƒë·ªô ·∫©m" not in sentence:
                    val = 70
            elif sensor == "light":
                unit = "lux"
                if "t·ªëi" in sentence:
                    op = "<"
                    val = 20
                elif "s√°ng" in sentence:
                    op = ">"
                    val = 30
            elif sensor == "fan":
                unit = "%"
                if len(match.groups()) > 1:
                    if match.group(2):
                        op = "="
                        val = int(match.group(2))
                        if val == 1:# 1 l√† m·ª©c th·∫•p nh·∫•t
                            val = 30
                        elif val == 2:
                            val = 70
                        elif val == 3:
                            val = 100
                elif any(kw in sentence for kw in ["nhanh", "m·∫°nh", "cao"]):
                    val = 100
                elif any(kw in sentence for kw in ["ch·∫≠m", "y·∫øu", "th·∫•p"]):
                    val = 30
                elif any(kw in sentence for kw in ["v·ª´a", "th∆∞·ªùng"]):
                    val = 70

            return {
                "sensor": sensor,
                "op": op,
                "value": val,
                "unit": unit
            }

    return None

# D·ª± ƒëo√°n intent + ƒëi·ªÅu ki·ªán
def nlp_pipeline(sentence: str) -> dict:
    condition = extract_numeric_condition(sentence)
    sentence_wo_condition = re.sub(r"khi .*|n·∫øu .*|l√∫c .*|khi tr·ªùi .*|n·∫øu tr·ªùi .*|l√∫c tr·ªùi .*|sau .*", "", sentence).strip()

    emb = get_sentence_embedding(sentence_wo_condition).unsqueeze(0)
    sims = {}
    for template, template_emb in template_embeddings.items():
        template_emb = template_emb.unsqueeze(0)
        sim = cosine_similarity(emb, template_emb)[0][0]
        sims[template] = sim
    best_template = max(sims, key=sims.get)

    return {
        "sentence": sentence,
        "intent": intent_templates[best_template],
        "matched_template": best_template,
        "similarity": float(sims[best_template]),
        "condition": condition
    }
