from transformers import pipeline, AutoTokenizer, AutoModel
import torch
from sklearn.metrics.pairwise import cosine_similarity
import re

device = 0 if torch.cuda.is_available() else -1

print(f"üì¶ ƒêang load ASR model l√™n {'GPU' if device == 0 else 'CPU'}...")

asr_pipeline = pipeline(
    "automatic-speech-recognition",
    model="whisper-small-vi",
    device=device
)

print("‚úÖ ASR model ƒë√£ s·∫µn s√†ng.")

print(f"üì¶ ƒêang load NLP model l√™n {'GPU' if device == 0 else 'CPU'}...")

tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base-v2", trust_remote_code=True)
model = AutoModel.from_pretrained("vinai/phobert-base-v2", trust_remote_code=True, use_safetensors=True)

print("‚úÖ NLP model ƒë√£ s·∫µn s√†ng.")

def get_sentence_embedding(sentence: str) -> torch.Tensor:
    """Chuy·ªÉn c√¢u th√†nh vector embedding trung b√¨nh (mean pooling)."""
    input_ids = tokenizer.encode(sentence, return_tensors='pt')
    with torch.no_grad():
        outputs = model(input_ids)
        last_hidden_state = outputs[0]  # (1, seq_len, hidden_dim)
        sentence_embedding = last_hidden_state.mean(dim=1)  # (1, hidden_dim)
    return sentence_embedding.squeeze(0)  # (hidden_dim,)

# M·∫´u c√¢u l·ªánh v√† intent t∆∞∆°ng ·ª©ng
intent_templates = {
    "b·∫≠t ƒë√®n": "TURN_ON_LIGHT",
    # "m·ªü ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n b·∫≠t": "TURN_ON_LIGHT",
    "kh√¥ng t·∫Øt ƒë√®n": "TURN_ON_LIGHT",
    # "ƒë√®n s√°ng": "TURN_ON_LIGHT",
    "t·ªëi qu√°": "TURN_ON_LIGHT",
    "kh√¥ng th·∫•y g√¨": "TURN_ON_LIGHT",
    "t·ªëi nh∆∞ m·ª±c": "TURN_ON_LIGHT",
    "t·ªëi r·ªìi": "TURN_ON_LIGHT",
    # "ƒë√®n t·∫Øt": "TURN_OFF_LIGHT",
    "t·∫Øt ƒë√®n": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng s√°ng": "TURN_OFF_LIGHT",
    # "ƒë√®n kh√¥ng m·ªü": "TURN_OFF_LIGHT",
    "kh√¥ng b·∫≠t ƒë√®n": "TURN_OFF_LIGHT",
    "s√°ng qu√°": "TURN_OFF_LIGHT",
    "ch√≥i qu√°": "TURN_OFF_LIGHT",
    "s√°ng r·ªìi": "TURN_OFF_LIGHT",

    "b·∫≠t qu·∫°t": "TURN_ON_FAN",
    "t·∫Øt qu·∫°t": "TURN_OFF_FAN",
    # "qu·∫°t ch·∫°y": "TURN_ON_FAN",
    "qu·∫°t kh√¥ng ng·ª´ng": "TURN_ON_FAN",
    "n√≥ng qu√°": "TURN_ON_FAN",
    "h·∫ßm qu√°": "TURN_ON_FAN",
    # "m·ªü qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t m·ªü": "TURN_ON_FAN",
    "qu·∫°t ng·ª´ng": "TURN_OFF_FAN",
    # "qu·∫°t kh√¥ng ch·∫°y": "TURN_OFF_FAN",
    "kh√¥ng t·∫Øt qu·∫°t": "TURN_ON_FAN",
    # "qu·∫°t kh√¥ng m·ªü": "TURN_OFF_FAN",
    "kh√¥ng b·∫≠t qu·∫°t": "TURN_OFF_FAN",
    "l·∫°nh qu√°": "TURN_OFF_FAN",
    # "r√©t qu√°": "TURN_OFF_FAN",

    "m·ªü c·ª≠a": "OPEN_DOOR",
    "m·ªü kh√≥a c·ª≠a": "OPEN_DOOR",
    "t·∫Øt kh√≥a c·ª≠a": "OPEN_DOOR",
    # "c·ª≠a m·ªü": "OPEN_DOOR",
    "kh√¥ng ƒë√≥ng c·ª≠a": "OPEN_DOOR",
    # "t√¥i chu·∫©n b·ªã ra ngo√†i": "OPEN_DOOR",
    "t√¥i s·∫Øp ra ngo√†i": "OPEN_DOOR",
    "t√¥i chu·∫©n b·ªã v·ªÅ nh√†": "OPEN_DOOR",
    # "t√¥i ƒëi ra ngo√†i": "OPEN_DOOR",
    "ƒë√≥ng c·ª≠a": "CLOSE_DOOR",
    "kh√≥a c·ª≠a": "CLOSE_DOOR",
    # "c·ª≠a ƒë√≥ng": "CLOSE_DOOR",
    "kh√¥ng m·ªü c·ª≠a": "CLOSE_DOOR",
    "t√¥i ra ngo√†i r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ nh√† r·ªìi": "CLOSE_DOOR",
    "t√¥i v√¥ nh√† r·ªìi": "CLOSE_DOOR",
    # "t√¥i v·ªÅ r·ªìi": "CLOSE_DOOR",

    "b·∫≠t ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_CLOSE_DOOR",
    "t·∫Øt ch·∫ø ƒë·ªô ban ƒë√™m": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_OPEN_DOOR",
    "b·∫≠t ch·∫ø ƒë·ªô an ninh": "CLOSE_DOOR_AND_TURN_ON_FACE_DETECTION",
    "t·∫Øt ch·∫ø ƒë·ªô an ninh": "OPEN_DOOR_AND_TURN_OFF_FACE_DETECTION",
    "b·∫≠t t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_OPEN_DOOR",
    "t·∫Øt t·∫•t c·∫£ thi·∫øt b·ªã": "TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_CLOSE_DOOR",
}

# H√†m embedding
def get_sentence_embedding(sentence: str) -> torch.Tensor:
    input_ids = tokenizer.encode(sentence, return_tensors='pt')
    with torch.no_grad():
        outputs = model(input_ids)
        last_hidden_state = outputs[0]
        sentence_embedding = last_hidden_state.mean(dim=1)
    return sentence_embedding.squeeze(0)

# L∆∞u s·∫µn embeddings c·ªßa intent m·∫´u
template_embeddings = {k: get_sentence_embedding(k) for k in intent_templates.keys()}

# Tr√≠ch xu·∫•t ƒëi·ªÅu ki·ªán s·ªë (temperature, humidity, time)
def extract_numeric_condition(sentence: str) -> dict:
    patterns = [
        # Nhi·ªát ƒë·ªô
        (
            r"(tr·ªùi)? (nhi·ªát[\s_]*ƒë·ªô|n√≥ng|l·∫°nh).*?(((\d+)\s*(ƒë·ªô[\s_]*[CcKk]?|¬∞[CcKk]?)?)|(th·∫•p|cao))?",
            "temperature"
        ),
        # ƒê·ªô ·∫©m
        (
            r"(tr·ªùi)? (ƒë·ªô[\s_]*·∫©m).*?((\d+)\s*(ph·∫ßn[\s_]*trƒÉm|%)?)?",
            "humidity"
        ),
        # √Ånh s√°ng
        {
            r"(tr·ªùi|bu·ªïi)?\s*\w*\s*(t·ªëi|s√°ng)",
            "light"
        },
        # Qu·∫°t
        {
            r"(m·ª©c|t·ªëc ƒë·ªô).*?((\d+)\s*(ph·∫ßn[\s_]*trƒÉm|%))|((nhanh|ch·∫≠m|v·ª´a|th∆∞·ªùng|m·∫°nh|y·∫øu|th·∫•p|cao)| \s* \w*)",
            "fan"
        }
        # Th·ªùi gian: gi·ªù, ph√∫t, gi√¢y (c√≥ th·ªÉ c√≥ ho·∫∑c kh√¥ng)
        (
            r"(l√∫c|sau|tr∆∞·ªõc).*?(?P<hour>\d+)\s*(gi·ªù|h|g)?(?:\s*(?P<minute>\d+)\s*(ph√∫t|p|m))?(?:\s*(?P<second>\d+)\s*(gi√¢y|s))?",
            "time"
        )
    ]

    for pattern, sensor in patterns:
        match = re.search(pattern, sentence)
        if match:
            # X√°c ƒë·ªãnh to√°n t·ª≠ logic
            op = "="
            if any(kw in sentence for kw in ["tr√™n", "sau", "n√≥ng", "nhi·ªÅu h∆°n"]):
                op = ">"
            elif any(kw in sentence for kw in ["d∆∞·ªõi", "tr∆∞·ªõc", "l·∫°nh", "√≠t h∆°n"]):
                op = "<"

            if sensor == "time":
                hour = int(match.group("hour")) if match.group("hour") else 0
                minute = int(match.group("minute")) if match.group("minute") else 0
                second = int(match.group("second")) if match.group("second") else 0
                return {
                    "sensor": "time",
                    "op": op,
                    "value": {
                        "hour": hour,
                        "minute": minute,
                        "second": second
                    },
                    "unit": "time"
                }
            if len(match.groups()) < 2:
                if sensor == "temperature":
                    if "n√≥ng" in sentence:
                        op = ">"
                        val = 30
                    elif "l·∫°nh" in sentence:
                        op = "<"
                        val = 20
                elif sensor == "humidity":
                    if "·∫©m" in sentence:
                        op = ">"
                        val = 70
                    elif "kh√¥" in sentence:
                        op = "<"
                        val = 30
            if sensor == "temperature":
                if "th·∫•p" in match.group(2):
                    op = "<"
                    val = 20
                elif "cao" in match.group(2):
                    op = ">"
                    val = 30
            elif sensor == "light":
                if "t·ªëi" in sentence:
                    op = "<"
                    val = 20
                elif "s√°ng" in sentence:
                    op = ">"
                    val = 30
            elif sensor == "fan":
                if any(kw in sentence for kw in ["nhanh", "m·∫°nh", "cao"]):
                    op = "="
                    val = 100
                elif any(kw in sentence for kw in ["ch·∫≠m", "y·∫øu", "th·∫•p"]):
                    op = "="
                    val = 30
                elif any(kw in sentence for kw in ["v·ª´a", "th∆∞·ªùng"]):
                    op = "="
                    val = 70

            val = int(match.group(2))
            unit = match.group(3) if match.lastindex and match.lastindex >= 3 else ""

            if sensor == "temperature":
                if unit.lower() in ["ƒë·ªô_k", "ƒë·ªô k", "¬∞k"]:
                    val -= 273
                unit = "¬∞C"
            elif sensor == "humidity":
                unit = "%"
            elif sensor == "light":
                unit = "lux"
            elif sensor == "fan":
                unit = "%"
            return {
                "sensor": sensor,
                "op": op,
                "value": val,
                "unit": unit.strip() if unit else ""
            }

    return None

def nlp_pipeline(sentence: str) -> dict:
    condition = extract_numeric_condition(sentence)
    sentence_wo_condition = re.sub(r"khi .*|n·∫øu .*|l√∫c .*|qu·∫°t .*", "", sentence).strip()

    emb = get_sentence_embedding(sentence_wo_condition).unsqueeze(0)
    sims = {}
    for template, template_emb in template_embeddings.items():
        template_emb = template_emb.unsqueeze(0)
        sim = cosine_similarity(emb, template_emb)[0][0]
        sims[template] = sim
    best_template = max(sims, key=sims.get)

    return {
        "sentence": sentence,
        "intent": intent_templates[best_template],
        "matched_template": best_template,
        "similarity": float(sims[best_template]),
        "condition": condition
    }
