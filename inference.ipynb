{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0919cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7639c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", trust_remote_code=True, use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5dc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence: str) -> torch.Tensor:\n",
    "    \"\"\"Chuy·ªÉn c√¢u th√†nh vector embedding trung b√¨nh (mean pooling).\"\"\"\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_state = outputs[0]  # (1, seq_len, hidden_dim)\n",
    "        sentence_embedding = last_hidden_state.mean(dim=1)  # (1, hidden_dim)\n",
    "    return sentence_embedding.squeeze(0)  # (hidden_dim,)\n",
    "\n",
    "# M·∫´u c√¢u l·ªánh v√† intent t∆∞∆°ng ·ª©ng\n",
    "intent_templates = {\n",
    "    \"b·∫≠t ƒë√®n\": \"TURN_ON_LIGHT\",\n",
    "    # \"m·ªü ƒë√®n\": \"TURN_ON_LIGHT\",\n",
    "    # \"ƒë√®n b·∫≠t\": \"TURN_ON_LIGHT\",\n",
    "    \"kh√¥ng t·∫Øt ƒë√®n\": \"TURN_ON_LIGHT\",\n",
    "    # \"ƒë√®n s√°ng\": \"TURN_ON_LIGHT\",\n",
    "    \"t·ªëi qu√°\": \"TURN_ON_LIGHT\",\n",
    "    \"kh√¥ng th·∫•y g√¨\": \"TURN_ON_LIGHT\",\n",
    "    \"t·ªëi nh∆∞ m·ª±c\": \"TURN_ON_LIGHT\",\n",
    "    \"t·ªëi r·ªìi\": \"TURN_ON_LIGHT\",\n",
    "    # \"ƒë√®n t·∫Øt\": \"TURN_OFF_LIGHT\",\n",
    "    \"t·∫Øt ƒë√®n\": \"TURN_OFF_LIGHT\",\n",
    "    # \"ƒë√®n kh√¥ng s√°ng\": \"TURN_OFF_LIGHT\",\n",
    "    # \"ƒë√®n kh√¥ng m·ªü\": \"TURN_OFF_LIGHT\",\n",
    "    \"kh√¥ng b·∫≠t ƒë√®n\": \"TURN_OFF_LIGHT\",\n",
    "    \"s√°ng qu√°\": \"TURN_OFF_LIGHT\",\n",
    "    \"ch√≥i qu√°\": \"TURN_OFF_LIGHT\",\n",
    "    \"s√°ng r·ªìi\": \"TURN_OFF_LIGHT\",\n",
    "\n",
    "    \"b·∫≠t qu·∫°t\": \"TURN_ON_FAN\",\n",
    "    \"t·∫Øt qu·∫°t\": \"TURN_OFF_FAN\",\n",
    "    # \"qu·∫°t ch·∫°y\": \"TURN_ON_FAN\",\n",
    "    \"qu·∫°t kh√¥ng ng·ª´ng\": \"TURN_ON_FAN\",\n",
    "    \"n√≥ng qu√°\": \"TURN_ON_FAN\",\n",
    "    \"h·∫ßm qu√°\": \"TURN_ON_FAN\",\n",
    "    # \"m·ªü qu·∫°t\": \"TURN_ON_FAN\",\n",
    "    # \"qu·∫°t m·ªü\": \"TURN_ON_FAN\",\n",
    "    \"qu·∫°t ng·ª´ng\": \"TURN_OFF_FAN\",\n",
    "    # \"qu·∫°t kh√¥ng ch·∫°y\": \"TURN_OFF_FAN\",\n",
    "    \"kh√¥ng t·∫Øt qu·∫°t\": \"TURN_ON_FAN\",\n",
    "    # \"qu·∫°t kh√¥ng m·ªü\": \"TURN_OFF_FAN\",\n",
    "    \"kh√¥ng b·∫≠t qu·∫°t\": \"TURN_OFF_FAN\",\n",
    "    \"l·∫°nh qu√°\": \"TURN_OFF_FAN\",\n",
    "    # \"r√©t qu√°\": \"TURN_OFF_FAN\",\n",
    "\n",
    "    \"m·ªü c·ª≠a\": \"OPEN_DOOR\",\n",
    "    \"m·ªü kh√≥a c·ª≠a\": \"OPEN_DOOR\",\n",
    "    \"t·∫Øt kh√≥a c·ª≠a\": \"OPEN_DOOR\",\n",
    "    # \"c·ª≠a m·ªü\": \"OPEN_DOOR\",\n",
    "    \"kh√¥ng ƒë√≥ng c·ª≠a\": \"OPEN_DOOR\",\n",
    "    # \"t√¥i chu·∫©n b·ªã ra ngo√†i\": \"OPEN_DOOR\",\n",
    "    \"t√¥i s·∫Øp ra ngo√†i\": \"OPEN_DOOR\",\n",
    "    \"t√¥i chu·∫©n b·ªã v·ªÅ nh√†\": \"OPEN_DOOR\",\n",
    "    # \"t√¥i ƒëi ra ngo√†i\": \"OPEN_DOOR\",\n",
    "    \"ƒë√≥ng c·ª≠a\": \"CLOSE_DOOR\",\n",
    "    \"kh√≥a c·ª≠a\": \"CLOSE_DOOR\",\n",
    "    # \"c·ª≠a ƒë√≥ng\": \"CLOSE_DOOR\",\n",
    "    \"kh√¥ng m·ªü c·ª≠a\": \"CLOSE_DOOR\",\n",
    "    \"t√¥i ra ngo√†i r·ªìi\": \"CLOSE_DOOR\",\n",
    "    # \"t√¥i v·ªÅ nh√† r·ªìi\": \"CLOSE_DOOR\",\n",
    "    \"t√¥i v√¥ nh√† r·ªìi\": \"CLOSE_DOOR\",\n",
    "    # \"t√¥i v·ªÅ r·ªìi\": \"CLOSE_DOOR\",\n",
    "\n",
    "    \"b·∫≠t ch·∫ø ƒë·ªô ban ƒë√™m\": \"TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_CLOSE_DOOR\",\n",
    "    \"t·∫Øt ch·∫ø ƒë·ªô ban ƒë√™m\": \"TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_OPEN_DOOR\",\n",
    "    \"b·∫≠t ch·∫ø ƒë·ªô an ninh\": \"CLOSE_DOOR_AND_TURN_ON_FACE_DETECTION\",\n",
    "    \"t·∫Øt ch·∫ø ƒë·ªô an ninh\": \"OPEN_DOOR_AND_TURN_OFF_FACE_DETECTION\",\n",
    "    \"b·∫≠t t·∫•t c·∫£ thi·∫øt b·ªã\": \"TURN_ON_LIGHT_AND_TURN_ON_FAN_AND_OPEN_DOOR\",\n",
    "    \"t·∫Øt t·∫•t c·∫£ thi·∫øt b·ªã\": \"TURN_OFF_LIGHT_AND_TURN_OFF_FAN_AND_CLOSE_DOOR\",\n",
    "}\n",
    "\n",
    "# H√†m embedding\n",
    "def get_sentence_embedding(sentence: str) -> torch.Tensor:\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_state = outputs[0]\n",
    "        sentence_embedding = last_hidden_state.mean(dim=1)\n",
    "    return sentence_embedding.squeeze(0)\n",
    "\n",
    "# L∆∞u s·∫µn embeddings c·ªßa intent m·∫´u\n",
    "template_embeddings = {k: get_sentence_embedding(k) for k in intent_templates.keys()}\n",
    "\n",
    "# Tr√≠ch xu·∫•t ƒëi·ªÅu ki·ªán s·ªë (temperature, humidity, time)\n",
    "def extract_numeric_condition(sentence: str) -> dict:\n",
    "    patterns = [\n",
    "        # Nhi·ªát ƒë·ªô\n",
    "        (# vd: nhi·ªát ƒë·ªô kho·∫£ng 30 ƒë·ªô C\n",
    "            r\"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) .*? (\\d+)? .*?\",\n",
    "            \"temperature\"\n",
    "        ),\n",
    "        (# vd: nhi·ªát ƒë·ªô 30 ƒë·ªô C\n",
    "            r\"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) (\\d+)? .*?\",\n",
    "            \"temperature\"\n",
    "        ),\n",
    "        (# vd: nhi·ªát ƒë·ªô cao/th·∫•p\n",
    "            r\"(nhi·ªát ƒë·ªô|n√≥ng|l·∫°nh) .*?\",\n",
    "            \"temperature\"\n",
    "        ),\n",
    "        (\n",
    "            r\"(n√≥ng|l·∫°nh)\",\n",
    "            \"temperature\"\n",
    "        ),\n",
    "        # ƒê·ªô ·∫©m\n",
    "        (# vd: ƒë·ªô ·∫©m kho·∫£ng 70%\n",
    "            r\"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) .*? (\\d+)?\",\n",
    "            \"humidity\"\n",
    "        ),\n",
    "        (# vd: ƒë·ªô ·∫©m 70%\n",
    "            r\"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) (\\d+)? .*?\",\n",
    "            \"humidity\"\n",
    "        ),\n",
    "        (# vd: ƒë·ªô ·∫©m cao/th·∫•p/kh√¥/·∫©m/√≠t/nhi·ªÅu\n",
    "            r\"(ƒë·ªô ·∫©m|n·ªìm|kh√¥) .*?\",\n",
    "            \"humidity\"\n",
    "        ),\n",
    "        (\n",
    "            r\"(·∫©m|n·ªìm|kh√¥)\",\n",
    "            \"humidity\"\n",
    "        ),\n",
    "        # √Ånh s√°ng\n",
    "        (\n",
    "            r\"(s√°ng|t·ªëi)\",\n",
    "            \"light\"\n",
    "        ),\n",
    "        # Qu·∫°t\n",
    "        (# vd: m·ª©c kho·∫£ng 70%\n",
    "            r\"(m·ª©c|t·ªëc ƒë·ªô|quay) .*? (\\d+)?\",\n",
    "            \"fan\"\n",
    "        ),\n",
    "        (# vd: m·ª©c 70%\n",
    "            r\"(m·ª©c|t·ªëc ƒë·ªô|quay) (\\d+)? .*?\",\n",
    "            \"fan\"\n",
    "        ),\n",
    "        (# vd: m·ª©c 1/2/3\n",
    "            r\"(m·ª©c|t·ªëc ƒë·ªô) (\\d+)?\",\n",
    "            \"fan\"\n",
    "        ),\n",
    "        (# vd: m·ª©c cao/th·∫•p/v·ª´a\n",
    "            r\"(m·ª©c|t·ªëc ƒë·ªô|quay) .*?\",\n",
    "            \"fan\"\n",
    "        ),\n",
    "        (\n",
    "            r\"(nhanh|m·∫°nh|cao|ch·∫≠m|y·∫øu|th·∫•p|v·ª´a|th∆∞·ªùng)\",\n",
    "            \"fan\"\n",
    "        ),\n",
    "        # Th·ªùi gian\n",
    "        (\n",
    "            r\"(sau)\\s*\"\n",
    "            r\"(?:(?P<hour>\\d+)\\s*(gi·ªù|h|g)\\s*)?\"\n",
    "            r\"(?:(?P<minute>\\d+)\\s*(ph√∫t|p|m)\\s*)?\"\n",
    "            r\"(?:(?P<second>\\d+)\\s*(gi√¢y|s))?\",\n",
    "            \"time\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for pattern, sensor in patterns:\n",
    "        match = re.search(pattern, sentence, re.IGNORECASE)\n",
    "        # print(pattern)\n",
    "        if match:\n",
    "            val = None\n",
    "            unit = \"\"\n",
    "            op = \"=\"\n",
    "\n",
    "            if any(kw in sentence for kw in [\"tr√™n\", \"n√≥ng\", \"nhi·ªÅu h∆°n\", \"·∫©m\", \"n·ªìm\", \"cao\"]):\n",
    "                op = \">\"\n",
    "                if \"ƒë·ªô ·∫©m\" in sentence and not any(kw in sentence for kw in [\"tr√™n\", \"nhi·ªÅu h∆°n\", \"n·ªìm\", \"cao\"]):\n",
    "                    op = \"=\"\n",
    "            elif any(kw in sentence for kw in [\"d∆∞·ªõi\", \"l·∫°nh\", \"√≠t h∆°n\", \"kh√¥\", \"th·∫•p\"]):\n",
    "                op = \"<\"\n",
    "            print(f\"match: {match.groups()}\")\n",
    "            if sensor == \"time\":\n",
    "                unit = \"seconds\"\n",
    "                hour = int(match.group(\"hour\")) if match.group(\"hour\") else 0\n",
    "                minute = int(match.group(\"minute\")) if match.group(\"minute\") else 0\n",
    "                second = int(match.group(\"second\")) if match.group(\"second\") else 0\n",
    "                val = hour * 3600 + minute * 60 + second\n",
    "            elif sensor == \"temperature\":\n",
    "                unit = \"¬∞C\"\n",
    "                if len(match.groups()) > 1:\n",
    "                    if match.group(2):\n",
    "                        op = \"=\"\n",
    "                        val = int(match.group(2))\n",
    "                        if any(kw in sentence for kw in [\"ƒë·ªô k\", \"¬∞k\", \"¬∞ka\", \"ƒë·ªô ka\", \"ƒë·ªô ca\", \"¬∞ca\"]) and \"ƒë·ªô kho·∫£ng\" not in sentence:\n",
    "                            val -= 273\n",
    "                elif any(kw in sentence for kw in [\"n√≥ng\", \"cao\"]):\n",
    "                    val = 30\n",
    "                elif any(kw in sentence for kw in [\"l·∫°nh\", \"th·∫•p\"]):\n",
    "                    val = 20\n",
    "            elif sensor == \"humidity\":\n",
    "                unit = \"%\"\n",
    "                if len(match.groups()) > 1:\n",
    "                    if match.group(2):\n",
    "                        op = \"=\"\n",
    "                        val = int(match.group(2))\n",
    "                elif any(kw in sentence for kw in [\"kh√¥\", \"th·∫•p\", \"√≠t\"]):\n",
    "                    val = 30\n",
    "                elif \"n·ªìm\" in sentence:\n",
    "                    val = 90\n",
    "                elif any(kw in sentence for kw in [\"cao\", \"nhi·ªÅu\"]):\n",
    "                    val = 70\n",
    "                elif \"·∫©m\" in sentence and \"ƒë·ªô ·∫©m\" not in sentence:\n",
    "                    val = 70\n",
    "            elif sensor == \"light\":\n",
    "                unit = \"lux\"\n",
    "                if \"t·ªëi\" in sentence:\n",
    "                    op = \"<\"\n",
    "                    val = 20\n",
    "                elif \"s√°ng\" in sentence:\n",
    "                    op = \">\"\n",
    "                    val = 30\n",
    "            elif sensor == \"fan\":\n",
    "                unit = \"%\"\n",
    "                if len(match.groups()) > 1:\n",
    "                    if match.group(2):\n",
    "                        op = \"=\"\n",
    "                        val = int(match.group(2))\n",
    "                        if val == 1:# 1 l√† m·ª©c th·∫•p nh·∫•t\n",
    "                            val = 30\n",
    "                        elif val == 2:\n",
    "                            val = 70\n",
    "                        elif val == 3:\n",
    "                            val = 100\n",
    "                elif any(kw in sentence for kw in [\"nhanh\", \"m·∫°nh\", \"cao\"]):\n",
    "                    val = 100\n",
    "                elif any(kw in sentence for kw in [\"ch·∫≠m\", \"y·∫øu\", \"th·∫•p\"]):\n",
    "                    val = 30\n",
    "                elif any(kw in sentence for kw in [\"v·ª´a\", \"th∆∞·ªùng\"]):\n",
    "                    val = 70\n",
    "\n",
    "            return {\n",
    "                \"sensor\": sensor,\n",
    "                \"op\": op,\n",
    "                \"value\": val,\n",
    "                \"unit\": unit\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "# D·ª± ƒëo√°n intent + ƒëi·ªÅu ki·ªán\n",
    "def nlp_pipeline(sentence: str) -> dict:\n",
    "    condition = extract_numeric_condition(sentence)\n",
    "    sentence_wo_condition = re.sub(r\"khi .*|n·∫øu .*|l√∫c .*|khi tr·ªùi .*|n·∫øu tr·ªùi .*|l√∫c tr·ªùi .*|sau .*\", \"\", sentence).strip()\n",
    "\n",
    "    emb = get_sentence_embedding(sentence_wo_condition).unsqueeze(0)\n",
    "    sims = {}\n",
    "    for template, template_emb in template_embeddings.items():\n",
    "        template_emb = template_emb.unsqueeze(0)\n",
    "        sim = cosine_similarity(emb, template_emb)[0][0]\n",
    "        sims[template] = sim\n",
    "    best_template = max(sims, key=sims.get)\n",
    "\n",
    "    return {\n",
    "        \"sentence\": sentence,\n",
    "        \"intent\": intent_templates[best_template],\n",
    "        \"matched_template\": best_template,\n",
    "        \"similarity\": float(sims[best_template]),\n",
    "        \"condition\": condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "958d2234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match: ('sau', '18', 'gi·ªù', '27', 'ph√∫t', None, None)\n",
      "\n",
      "üü¢ Input: b·∫≠t qu·∫°t sau 18 gi·ªù 27 ph√∫t n·ªØa\n",
      "‚û° Intent: TURN_ON_FAN\n",
      "‚û° Condition: {'sensor': 'time', 'op': '=', 'value': 66420, 'unit': 'seconds'}\n",
      "‚û° Matched template: b·∫≠t qu·∫°t\n",
      "‚û° Similarity: 1.0000\n",
      "match: ('sau', None, None, '27', 'ph√∫t', None, None)\n",
      "\n",
      "üü¢ Input: b·∫≠t qu·∫°t sau 27 ph√∫t √°\n",
      "‚û° Intent: TURN_ON_FAN\n",
      "‚û° Condition: {'sensor': 'time', 'op': '=', 'value': 1620, 'unit': 'seconds'}\n",
      "‚û° Matched template: b·∫≠t qu·∫°t\n",
      "‚û° Similarity: 1.0000\n",
      "match: ('m·ª©c', '70')\n",
      "\n",
      "üü¢ Input: b·∫≠t qu·∫°t m·ª©c 70%\n",
      "‚û° Intent: TURN_ON_FAN\n",
      "‚û° Condition: {'sensor': 'fan', 'op': '=', 'value': 70, 'unit': '%'}\n",
      "‚û° Matched template: b·∫≠t qu·∫°t\n",
      "‚û° Similarity: 0.3980\n",
      "match: ('m·ª©c', '1')\n",
      "\n",
      "üü¢ Input: b·∫≠t qu·∫°t m·ª©c 1\n",
      "‚û° Intent: TURN_ON_FAN\n",
      "‚û° Condition: {'sensor': 'fan', 'op': '=', 'value': 30, 'unit': '%'}\n",
      "‚û° Matched template: b·∫≠t qu·∫°t\n",
      "‚û° Similarity: 0.7622\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"b·∫≠t qu·∫°t sau 18 gi·ªù 27 ph√∫t n·ªØa\",\n",
    "    \"b·∫≠t qu·∫°t sau 27 ph√∫t √°\",\n",
    "    \"b·∫≠t qu·∫°t m·ª©c 70%\",\n",
    "    \"b·∫≠t qu·∫°t m·ª©c 1\",\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    result = nlp_pipeline(s)\n",
    "    print(f\"\\nüü¢ Input: {s}\")\n",
    "    print(f\"‚û° Intent: {result['intent']}\")\n",
    "    if result[\"condition\"]:\n",
    "        print(f\"‚û° Condition: {result['condition']}\")\n",
    "    print(f\"‚û° Matched template: {result['matched_template']}\")\n",
    "    print(f\"‚û° Similarity: {result['similarity']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio_hutech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
